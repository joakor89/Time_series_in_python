{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1d576fba-2ff5-496f-b5ea-cbc0b08d42c1",
   "metadata": {},
   "source": [
    "# Remembering The Past with Long Short-Term Memory (LSTM)\n",
    "\n",
    "#### Loading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8918d2b2-3e2f-4e71-8bcd-069d0ae3c521",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Numerical Computing\n",
    "import numpy as np\n",
    "# Data Manipulation\n",
    "import pandas as pd\n",
    "# Data manipulation\n",
    "import datetime\n",
    "# Data Visualization\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Data Scalation\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# Deep Learning\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import Model, Sequential\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.losses import MeanSquaredError\n",
    "from tensorflow.keras.metrics import MeanAbsoluteError\n",
    "\n",
    "from tensorflow.keras.layers import Dense, Conv1D, LSTM, Lambda, Reshape, RNN, LSTMCell\n",
    "\n",
    "# Warnings\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f1a18b28-d4d2-4ba9-9301-575d74017985",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.optimizers import Adam\n",
    "# Cambia esta l√≠nea\n",
    "# from tensorflow.keras.optimizers import Adam\n",
    "# Por esta\n",
    "from tensorflow.keras.optimizers.legacy import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "75c5483f-fac4-4644-978a-2b74755cb598",
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f1425e3-722b-41d0-bcb1-fc9130fc01dd",
   "metadata": {},
   "source": [
    "##### Visualization Set Up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bf197629-2c31-4873-bf67-5682ac669d3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams['figure.figsize'] = (10, 7.5)\n",
    "plt.rcParams['axes.grid'] = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "349e89e6-94ee-4200-9842-e4df090264ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.15.0\n"
     ]
    }
   ],
   "source": [
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bdfb3972-d9de-4c5a-9d15-f62f112fe569",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Numerical & Tensorflow Setting Seeds\n",
    "tf.random.set_seed(42)\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e0750a9-0171-4326-972e-b6f0166ab956",
   "metadata": {},
   "source": [
    "#### Loading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "09b0f667-a287-41aa-890e-1d198f52e3bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(12285, 5) (3510, 5) (1756, 5)\n"
     ]
    }
   ],
   "source": [
    "train_df = pd.read_csv('/Users/isisromero/desktop/time_series/preprocessed/train.csv', index_col=0)\n",
    "val_df = pd.read_csv('/Users/isisromero/desktop/time_series/preprocessed/val.csv', index_col=0)\n",
    "test_df = pd.read_csv('/Users/isisromero/desktop/time_series/preprocessed/test.csv', index_col=0)\n",
    "\n",
    "print(train_df.shape, val_df.shape, test_df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "498851e0-5c0b-4f55-9c73-dbadb907475d",
   "metadata": {},
   "source": [
    "##### Setting Data Window Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a0e42da3-363e-4a8f-ab98-a6d3004025e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataWindow():\n",
    "    def __init__(self, input_width, label_width, shift, \n",
    "                 train_df=train_df, val_df=val_df, test_df=test_df, \n",
    "                 label_columns=None):\n",
    "        \n",
    "        self.train_df = train_df\n",
    "        self.val_df = val_df\n",
    "        self.test_df = test_df\n",
    "        \n",
    "        self.label_columns = label_columns\n",
    "        if label_columns is not None:\n",
    "            self.label_columns_indices = {name: i for i, name in enumerate(label_columns)}\n",
    "        self.column_indices = {name: i for i, name in enumerate(train_df.columns)}\n",
    "        \n",
    "        self.input_width = input_width\n",
    "        self.label_width = label_width\n",
    "        self.shift = shift\n",
    "        \n",
    "        self.total_window_size = input_width + shift\n",
    "        \n",
    "        self.input_slice = slice(0, input_width)\n",
    "        self.input_indices = np.arange(self.total_window_size)[self.input_slice]\n",
    "        \n",
    "        self.label_start = self.total_window_size - self.label_width\n",
    "        self.labels_slice = slice(self.label_start, None)\n",
    "        self.label_indices = np.arange(self.total_window_size)[self.labels_slice]\n",
    "    \n",
    "    def split_to_inputs_labels(self, features):\n",
    "        inputs = features[:, self.input_slice, :]\n",
    "        labels = features[:, self.labels_slice, :]\n",
    "        if self.label_columns is not None:\n",
    "            labels = tf.stack(\n",
    "                [labels[:,:,self.column_indices[name]] for name in self.label_columns],\n",
    "                axis=-1\n",
    "            )\n",
    "        inputs.set_shape([None, self.input_width, None])\n",
    "        labels.set_shape([None, self.label_width, None])\n",
    "        \n",
    "        return inputs, labels\n",
    "    \n",
    "    def plot(self, model=None, plot_col='traffic_volume', max_subplots=3):\n",
    "        inputs, labels = self.sample_batch\n",
    "        \n",
    "        plt.figure(figsize=(12, 8))\n",
    "        plot_col_index = self.column_indices[plot_col]\n",
    "        max_n = min(max_subplots, len(inputs))\n",
    "        \n",
    "        for n in range(max_n):\n",
    "            plt.subplot(3, 1, n+1)\n",
    "            plt.ylabel(f'{plot_col} [scaled]')\n",
    "            plt.plot(self.input_indices, inputs[n, :, plot_col_index],\n",
    "                     label='Inputs', marker='.', zorder=-10)\n",
    "\n",
    "            if self.label_columns:\n",
    "              label_col_index = self.label_columns_indices.get(plot_col, None)\n",
    "            else:\n",
    "              label_col_index = plot_col_index\n",
    "\n",
    "            if label_col_index is None:\n",
    "              continue\n",
    "\n",
    "            plt.scatter(self.label_indices, labels[n, :, label_col_index],\n",
    "                        edgecolors='k', marker='s', label='Labels', c='green', s=64)\n",
    "            if model is not None:\n",
    "              predictions = model(inputs)\n",
    "              plt.scatter(self.label_indices, predictions[n, :, label_col_index],\n",
    "                          marker='X', edgecolors='k', label='Predictions',\n",
    "                          c='red', s=64)\n",
    "\n",
    "            if n == 0:\n",
    "              plt.legend()\n",
    "\n",
    "        plt.xlabel('Time (h)')\n",
    "        \n",
    "    def make_dataset(self, data):\n",
    "        data = np.array(data, dtype=np.float32)\n",
    "        ds = tf.keras.preprocessing.timeseries_dataset_from_array(\n",
    "            data=data,\n",
    "            targets=None,\n",
    "            sequence_length=self.total_window_size,\n",
    "            sequence_stride=1,\n",
    "            shuffle=True,\n",
    "            batch_size=32\n",
    "        )\n",
    "        \n",
    "        ds = ds.map(self.split_to_inputs_labels)\n",
    "        return ds\n",
    "    \n",
    "    @property\n",
    "    def train(self):\n",
    "        return self.make_dataset(self.train_df)\n",
    "    \n",
    "    @property\n",
    "    def val(self):\n",
    "        return self.make_dataset(self.val_df)\n",
    "    \n",
    "    @property\n",
    "    def test(self):\n",
    "        return self.make_dataset(self.test_df)\n",
    "    \n",
    "    @property\n",
    "    def sample_batch(self):\n",
    "        result = getattr(self, '_sample_batch', None)\n",
    "        if result is None:\n",
    "            result = next(iter(self.train))\n",
    "            self._sample_batch = result\n",
    "        return result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51a62947-99ee-4849-ad1e-5eb27811da0e",
   "metadata": {},
   "source": [
    "##### Setting Compile & Fit Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8f1050d3-1dc5-4248-a2fc-f60463855218",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compile_and_fit(model, window, patience=3, max_epochs=50):\n",
    "    early_stopping = EarlyStopping(monitor='val_loss',\n",
    "                                   patience=patience,\n",
    "                                   mode='min')\n",
    "    \n",
    "    model.compile(loss=MeanSquaredError(),\n",
    "                  optimizer=Adam(),\n",
    "                  metrics=[MeanAbsoluteError()])\n",
    "    \n",
    "    history = model.fit(window.train,\n",
    "                       epochs=max_epochs,\n",
    "                       validation_data=window.val,\n",
    "                       callbacks=[early_stopping])\n",
    "    \n",
    "    return history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "96c55755-9116-4cc8-88b8-590afbef1f79",
   "metadata": {},
   "outputs": [],
   "source": [
    "column_indices = {name: i for i, name in enumerate(train_df.columns)}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2257575f-203c-41e6-bfdd-88d92854b823",
   "metadata": {},
   "source": [
    "### Long Short-Term Memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c4f3dee-e769-417d-83d3-615cce4b2cc6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
